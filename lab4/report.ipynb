{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as pt\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d(nn.Module):\n",
    "    def __init__(self, in_channels:int, out_channels:int, kernel_size:int=3, \n",
    "                 stride:int=1, padding:int=0, bias:bool=True) -> None:\n",
    "        super(Conv1d, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.pad = padding\n",
    "        self.ker_size = kernel_size        \n",
    "        self.out_ch = out_channels\n",
    "        self.kernel = nn.Parameter(nn.init.xavier_normal_(pt.randn(out_channels, in_channels, kernel_size)))\n",
    "        self.bias = None\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(pt.zeros(out_channels))\n",
    "\n",
    "    def forward(self, x):    \n",
    "        # xï¼š(batch_size, in_channel, in_len)\n",
    "        out_len = (x.shape[2] + 2*self.pad - self.ker_size)//self.stride + 1\n",
    "        x = nn.functional.pad(x, (self.pad, self.pad), \"constant\", 0)\n",
    "        \n",
    "        # (batch_size, in_ch, 1, in_len) -> (batch_size, in_ch*ker_size, out_len)\n",
    "        x_unfold = nn.functional.unfold(x[:,:,None,:], \n",
    "                                        kernel_size=(1,self.ker_size), stride=(1,self.stride))\n",
    "        out = self.kernel.view(self.out_ch, -1).matmul(x_unfold).view(x.shape[0], self.out_ch, out_len)\n",
    "                 \n",
    "        if self.bias is not None:\n",
    "            out += self.bias[None,:,None]\n",
    " \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3449, -0.4838,  0.8674,  ...,  1.0192,  0.7717,  0.3107],\n",
       "         [ 0.2144, -0.0657, -0.2448,  ..., -1.3025, -0.5207, -1.1039],\n",
       "         [ 0.1322,  0.2191,  0.7026,  ..., -0.1720,  0.2691, -1.0479],\n",
       "         ...,\n",
       "         [-0.4344,  0.7108, -1.1424,  ...,  0.2083, -0.6631,  0.3330],\n",
       "         [ 0.7642,  0.5890, -0.7912,  ...,  0.6954, -1.8800,  0.1798],\n",
       "         [ 0.0536, -0.1230,  0.7764,  ...,  0.5833, -0.8045,  0.6417]],\n",
       "\n",
       "        [[ 0.4509,  1.3623,  0.4830,  ...,  1.0819, -0.1903,  0.7669],\n",
       "         [ 0.3703,  0.4546, -1.9401,  ...,  0.3224,  0.5016,  0.8625],\n",
       "         [-0.4299, -1.2423, -0.6637,  ..., -0.9293, -0.6359, -0.4731],\n",
       "         ...,\n",
       "         [ 0.4017, -1.1916, -0.0102,  ...,  0.8748, -0.7221, -0.1131],\n",
       "         [-1.8109,  1.1097,  0.3012,  ..., -0.2892, -0.9557,  0.7772],\n",
       "         [ 0.5414,  0.3040,  1.5627,  ...,  0.0882,  1.8263, -0.2107]]],\n",
       "       grad_fn=<AsStridedBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pt.randn(2,3,256)\n",
    "m = Conv1d(3,8,3,1,1)\n",
    "b=m(a)\n",
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
